import asyncio
import logging
import re
import os
from urllib.parse import urlparse
import requests
from bs4 import BeautifulSoup
import yt_dlp
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


BOT_TOKEN = "7553558482:AAEuDLjqz-a7uHXKzjPpmMu8CGbhqJqXsDc"

class VideoDownloadBot:
    def __init__(self):
        self.download_folder = "downloads"
        os.makedirs(self.download_folder, exist_ok=True)
    
    def extract_urls(self, text):
        """–í–∏—Ç—è–≥—É—î –≤—Å—ñ URL –∑ —Ç–µ–∫—Å—Ç—É"""
        url_pattern = re.compile(
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        )
        return url_pattern.findall(text)
    
    def is_video_url(self, url):
     
        video_domains = [
            'youtube.com', 'youtu.be', 'vimeo.com', 'dailymotion.com',
            'tiktok.com', 'instagram.com', 'twitter.com', 'x.com',
            'facebook.com', 'twitch.tv'
        ]
        
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        return any(video_domain in domain for video_domain in video_domains)
    
    async def download_video(self, url, max_size_mb=50):
      
        try:
            ydl_opts = {
                'format': 'best[filesize<50M]/best',
                'outtmpl': f'{self.download_folder}/%(title)s.%(ext)s',
                'noplaylist': True,
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                title = info.get('title', 'Unknown')
                duration = info.get('duration', 0)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É
                filesize = info.get('filesize') or info.get('filesize_approx', 0)
                if filesize and filesize > max_size_mb * 1024 * 1024:
                    return None, f"–í—ñ–¥–µ–æ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–µ ({filesize/(1024*1024):.1f}MB). –ú–∞–∫—Å–∏–º—É–º {max_size_mb}MB"
                
             
                ydl.download([url])
                
            
                for file in os.listdir(self.download_folder):
                    if title.replace('/', '_') in file or info.get('id', '') in file:
                        filepath = os.path.join(self.download_folder, file)
                        return filepath, None
                        
                return None, "–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è"
                
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ {url}: {e}")
            return None, f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {str(e)}"
    
    def get_page_description(self, url):
      
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ü—Ä–æ–±—É—î–º–æ —Ä—ñ–∑–Ω—ñ —Å–ø–æ—Å–æ–±–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ–ø–∏—Å—É
            description = None
            
            # Meta description
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc:
                description = meta_desc.get('content', '').strip()
            
            # Open Graph description
            if not description:
                og_desc = soup.find('meta', attrs={'property': 'og:description'})
                if og_desc:
                    description = og_desc.get('content', '').strip()
            
            # Twitter description
            if not description:
                twitter_desc = soup.find('meta', attrs={'name': 'twitter:description'})
                if twitter_desc:
                    description = twitter_desc.get('content', '').strip()
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
            title = soup.find('title')
            title_text = title.text.strip() if title else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"
            
            # –Ø–∫—â–æ –Ω–µ–º–∞—î –æ–ø–∏—Å—É, –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            if not description:
                paragraph = soup.find('p')
                if paragraph:
                    description = paragraph.text.strip()[:200] + "..."
            
            return {
                'title': title_text[:100],
                'description': description[:300] if description else "–û–ø–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π",
                'url': url
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ–ø–∏—Å—É –¥–ª—è {url}: {e}")
            return {
                'title': "–ü–æ–º–∏–ª–∫–∞",
                'description': f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ–ø–∏—Å: {str(e)}",
                'url': url
            }


bot = VideoDownloadBot()

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–ª—è—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º–∏"""
    message = update.message
    text = message.text
    
    # –í–∏—Ç—è–≥—É—î–º–æ –≤—Å—ñ URL –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    urls = bot.extract_urls(text)
    
    if not urls:
        return
    
    await message.reply_text("üîç –ó–Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è! –û–±—Ä–æ–±–ª—è—é...")
    
    for url in urls:
        try:
            if bot.is_video_url(url):
                # –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—ñ–¥–µ–æ
                await message.reply_text(f"üìπ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –≤—ñ–¥–µ–æ –∑: {url}")
                
                filepath, error = await bot.download_video(url)
                
                if filepath and os.path.exists(filepath):
                    # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤—ñ–¥–µ–æ
                    with open(filepath, 'rb') as video_file:
                        await message.reply_video(
                            video=video_file,
                            caption=f"üìπ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑: {url}"
                        )
                    
                    # –í–∏–¥–∞–ª—è—î–º–æ —Ñ–∞–π–ª –ø—ñ—Å–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏
                    os.remove(filepath)
                    
                elif error:
                    await message.reply_text(f"‚ùå {error}")
                    # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—ñ–¥–µ–æ, —Ä–æ–±–∏–º–æ –æ–ø–∏—Å
                    page_info = bot.get_page_description(url)
                    description_text = f"üìÑ **{page_info['title']}**\n\n{page_info['description']}\n\nüîó {page_info['url']}"
                    await message.reply_text(description_text, parse_mode='Markdown')
            else:
                # –î–ª—è –Ω–µ-–≤—ñ–¥–µ–æ –ø–æ—Å–∏–ª–∞–Ω—å —Ä–æ–±–∏–º–æ –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å
                await message.reply_text(f"üìÑ –°—Ç–≤–æ—Ä—é—é –æ–ø–∏—Å –¥–ª—è: {url}")
                
                page_info = bot.get_page_description(url)
                description_text = f"üìÑ **{page_info['title']}**\n\n{page_info['description']}\n\nüîó {page_info['url']}"
                
                await message.reply_text(description_text, parse_mode='Markdown')
                
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ URL {url}: {e}")
            await message.reply_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {url}: {str(e)}")

def main():
  
    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–æ–¥–∞—Ç–æ–∫
    application = Application.builder().token(BOT_TOKEN).build()
    
    # –î–æ–¥–∞—î–º–æ –æ–±—Ä–æ–±–Ω–∏–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ! –ù–∞–¥—Å–∏–ª–∞–π—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏...")
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –±–æ—Ç–∞
    application.run_polling()

if __name__ == '__main__':
    main()
